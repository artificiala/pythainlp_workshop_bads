{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop Notebook 2: Text Classification on True Voice Intent Dataset with PyThaiNLP\n",
    "\n",
    "\n",
    "\n",
    "Updated: 31 October 2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "True Voice Intent Dataset : https://github.com/PyThaiNLP/truevoice-intent\n",
    "\n",
    "Intent Dataset from Customer Service Phone Calls Transcribed by TrueVoice's Mari.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required packages\n",
    "\n",
    "\n",
    "Visualization\n",
    "  - `matplotlib`\n",
    "  - `seaborn`\n",
    "  \n",
    "Machine Learning\n",
    "  - `sklearn`\n",
    "  \n",
    "Dataframe, Data structure\n",
    "  - `pandas`\n",
    "  - `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --user -q --pre pythainlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user -q matplotlib==3.1.0 numpy pandas sklearn seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.ulmfit import ungroup_emoji\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUEVOICE_INTENT_DIR = \"../data/truevoice_intent\"\n",
    "\n",
    "truevoice_dataset_path = { \n",
    "    \"train\": os.path.join(TRUEVOICE_INTENT_DIR, \"mari_train.csv\"),\n",
    "    \"test\": os.path.join(TRUEVOICE_INTENT_DIR, \"mari_test.csv\")\n",
    "}\n",
    "truevoice_dataset_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truevoice_dataset = {\n",
    "    \"train\": pd.read_csv(truevoice_dataset_path[\"train\"]),\n",
    "    \"test\": pd.read_csv(truevoice_dataset_path[\"test\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2  Customer voice transcription and Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truevoice_dataset[\"train\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of examples for the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truevoice_dataset[\"train\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truevoice_dataset[\"test\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percentage of class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_name in [\"train\", \"test\"]:\n",
    "    print(\"set:\", set_name)\n",
    "    print(\"\")\n",
    "    print(truevoice_dataset[set_name]['destination'].value_counts() / truevoice_dataset[set_name].shape[0] * 100)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will use `CountVectorizer` from scikit-learn [link](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html).\n",
    "\n",
    "- `CountVectorizer` converts a collection of text documents to a matrix of token counts\n",
    "\n",
    "```python\n",
    "documents = [\"ฉันขึ้นรถไฟ\", \"ฉันชอบรถไฟฟ้า\", \"ฉันชอบรถไฟ รถไฟ\"]\n",
    "\n",
    "vocabulary = Set['ขึ้น', 'ฉัน', 'ชอบ', 'รถไฟ', 'รถไฟฟ้า']\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"ฉันขึ้นรถไฟ\", \"ฉันชอบรถไฟฟ้า\", \"ฉันชอบรถไฟ รถไฟ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoizer = CountVectorizer(tokenizer=word_tokenize)\n",
    "X = vectoizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectoizer.get_feature_names(), \"\\n\")\n",
    "for i, document in enumerate(documents):\n",
    "    tokens = word_tokenize(document)\n",
    "    print(document,\"\\n\", tokens,\"\\n\", X.toarray()[i])\n",
    "    print(\"\")\n",
    "                             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function to process texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    text = text.lower()\n",
    "    words = word_tokenize(text, keep_whitespace=False)    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_text(\"Hello ฉัน\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Define preprocessing/training pipeline\n",
    "\n",
    "1. Vectorize text with `CountVectorizer`.\n",
    "2. Normalize Count Vector with L2 norm.\n",
    "3. Fit the training data with __Linear Support Vector Classification__ ([LinearSVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html)).\n",
    "\n",
    "\n",
    "![title](images/svc.png)\n",
    "\n",
    "Image from: https://scikit-learn.org/stable/modules/svm.html#svm-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer(tokenizer=process_text,\n",
    "                                         ngram_range=(1,2))),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('classifier', LinearSVC(max_iter=25000, random_state=1, class_weight=\"balanced\")),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = truevoice_dataset[\"train\"]['texts'], truevoice_dataset[\"train\"][\"destination\"]\n",
    "X_test, y_test = truevoice_dataset[\"test\"]['texts'], truevoice_dataset[\"test\"][\"destination\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Fit traing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Make prediction from testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, x in enumerate(X_test[0:5]):\n",
    "    print(\"question: {}\".format(x))\n",
    "    print(\"groundtruth: {}\".format(y_test[index]))\n",
    "    print(\"predition: {}\".format(predictions[index]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Question 1:__ How many examples in test set `y_test` that are predicted incorrectly.\n",
    "\n",
    "\n",
    "Hint:\n",
    "```python\n",
    ">>> print(predictions.shape, y_test.shape)\n",
    "(3236,) (3236,)\n",
    "\n",
    ">>> print(predictions[0])\n",
    "promotions\n",
    "\n",
    ">>> print(y_test[0])\n",
    "promotions\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write down the code to find the answer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = X_test[predictions != y_test].index\n",
    "print(\"Number of examples that predicted incorrectly = {}\".format(len(indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in indices[:15]:\n",
    "    print(index, X_test.iloc[index])\n",
    "    print(\" groundtruth:\", y_test.iloc[index])\n",
    "    print(\" prediction:\", predictions[index])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Metrics\n",
    "\n",
    "__Per-class Accuracy__\n",
    "\n",
    "$$\n",
    "\\text{class_accuracy}(i) = \\frac{\\text{Number of correct prediction for class } i}{\\text{Number of samples are in class } i}\n",
    "$$\n",
    "\n",
    "\n",
    "__Per-class F1__\n",
    "\n",
    "$$\n",
    "\\text{class_f1}(i) = \\frac{ 2 \\cdot (\\text{class_precision}(i) \\cdot \\text{class_recall}(i)) }{ \\text{class_precision}(i) + \\text{class_recall}(i) }\n",
    "$$\n",
    "\n",
    "\n",
    "__Per-class Precision__\n",
    "\n",
    "$$\n",
    "\\text{class_precision}(i) =  \\frac{\\text{Number of correct prediction for class } i}{\\text{Number of correct prediction for class } i + \\text{Number of samples in other classes predicted as class } i \\text{ (False Positive)}}\n",
    "$$\n",
    "\n",
    "__Per-class Recall__\n",
    "\n",
    "$$\n",
    "\\text{class_recall}(i) =  \\frac{\\text{Number of correct prediction for class } i}{\\text{Number of correct prediction for class } i + \\text{Number of samples in class } i  \\text{ that predicted as other classes (False Negative)}}\n",
    "$$\n",
    "\n",
    "----\n",
    "\n",
    "Reference: https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder_fit = onehot_encoder.fit(truevoice_dataset[\"test\"][\"destination\"][:,None])\n",
    "predictions_onehot = onehot_encoder_fit.transform(predictions[:,None]).toarray()\n",
    "\n",
    "y_onehot = onehot_encoder_fit.transform(truevoice_dataset[\"test\"][\"destination\"][:,None]).toarray()\n",
    "    \n",
    "nb_class = 7\n",
    "for i in range(nb_class):\n",
    "    print(\"Class: \", i, )\n",
    "    print(\"Accuracy: {:.2f} \".format((predictions_onehot[:,i] == y_onehot[:,i]).mean()))\n",
    "    print(\"F1-score: {:.2f} \".format(f1_score(predictions_onehot[:,i], y_onehot[:,i])))\n",
    "    print(\"Precision: {:.2f} \".format(precision_score(predictions_onehot[:,i],y_onehot[:,i])))\n",
    "    print(\"Recall: {:.2f} \".format(recall_score(predictions_onehot[:,i], y_onehot[:,i])))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall Accuracy\n",
    "\n",
    "$$\n",
    "\\text{Overall accuracy} = \\frac{\\text{Number of correct prediction}}{\\text{Number of samples}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overall accuracy \")\n",
    "accuracy_score(predictions_onehot, y_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "\n",
    "\n",
    "Change from one hot encoding (e.g. `[0, 0, 0, 0, 0, 0, 1]`)\n",
    "to the original label (e.g. `\"true money\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_orig = onehot_encoder.inverse_transform(predictions_onehot)\n",
    "predictions_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_orig = onehot_encoder.inverse_transform(y_onehot)\n",
    "y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_orig, predictions_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(onehot_encoder.categories_[0])\n",
    "print(\"labels\", labels)\n",
    "\n",
    "\n",
    "plt.figure(figsize = (8,8))\n",
    "ax = plt.subplot(111, aspect = 'equal')\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_orig, predictions_orig),\n",
    "            annot=True, cmap=\"rocket\", fmt=\"d\",\n",
    "            xticklabels=labels,\n",
    "            yticklabels=labels,\n",
    "            square=True)\n",
    "\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
